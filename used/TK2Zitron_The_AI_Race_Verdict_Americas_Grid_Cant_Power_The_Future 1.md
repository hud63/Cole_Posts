According to a stunning new analysis circulating Silicon Valley, "Everywhere we went in China, people treated the availability of energy as a given" while American AI developers are supposedly forced to build private power plants or face rolling blackouts. The article warns that "China's strategic energy surplus creates an insurmountable lead" and proclaims the AI race is already overâ€”decided not by algorithms, but by electrical grids.

Let me do some quick math for you.

The U.S. Department of Energy warns that blackouts could increase 100x by 2030 if current trends continue. Sounds terrifying, right? Except the DOE released this in July 2025â€”under an administration that has every political incentive to declare infrastructure crisis to justify massive spending. The report conveniently blames "radical green agenda of past administrations" while projecting AI data center demand will require adding 100 GW of power by 2030.

Here's what they're not telling you: Deloitte projects AI data centers will need 123 gigawatts by 2035â€”a 30x increase from 4 GW in 2024. That's roughly the power consumption of 123 million homes. The article breathlessly claims a "five-acre data center" could jump from 5 to 50 megawatts when adding GPUs.

Okay. So where's this actually happening?

The International Energy Agency projects global data center electricity demand will reach 945 terawatt-hours by 2030â€”slightly more than Japan's entire consumption. Notice they said "global," not just the U.S. China's getting hit with this too. The Ember 2025 China Energy Transition Review shows that in H1 2025, China's clean generation growth actually exceeded demand growth, cutting fossil fuel use by 2%. Translation: China's also scrambling to figure out how to power AI.

But here's my favorite part: the article claims China maintains "nearly 100% greater" generation capacity than peak demandâ€”this magical "strategic abundance." The reality? China added 105 GW of solar in the first four months of 2025 alone because their coal plants are running at a record low 46.4% capacity utilization. They're not running on "strategic surplus"â€”they're desperately building renewables because their existing infrastructure can't efficiently handle the load.

And that bit about American developers spending all their time "optimizing code to be energy-efficient" while Chinese developers freely "brute-force" problems? NERC's 2025 Summer Reliability Assessment shows the U.S. added 10 GW of new capacity over last summer. PJM Interconnectionâ€”the nation's largest grid operatorâ€”just failed to meet its reserve margin for the first time ever, which is genuinely concerning. But you know what's not happening? American AI companies aren't shutting down. They're signing deals directly with utilities, restarting nuclear plants, and yes, building on-site generation.

The real story here isn't "China won because they have infinite electricity and we're stuck in the dark." The real story is that AI's power requirements are catching every grid operator worldwide completely off guard, and everyoneâ€”China includedâ€”is frantically trying to scale infrastructure that takes decades to build for a technology that doubled its energy consumption in 18 months.

But sure, let's declare the race "over" because Chinese officials said "energy is a given" during a carefully orchestrated Silicon Valley tour.

You can spot the grift when they tell you the competition ended before most people knew it started.

---

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude <noreply@anthropic.com>
